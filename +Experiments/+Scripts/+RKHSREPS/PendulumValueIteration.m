%close all;

%Common.clearClasses();
%clear all;
%clc;

%MySQL.mym('closeall');
error('check whether the script works in the new toolbox!');
category = 'test';
experimentName = 'test';
numTrials = 10;
numIterations = 20;

configuredTask = Experiments.Tasks.SwingUpTaskPeriodic(true);

%%
configuredLearner = Experiments.Learner.StepBasedRKHSREPS('RKHSREPSPeriodic');

% feature configurator
configuredFeatures = Experiments.Features.FeatureRBFKernelStatesPeriodic;
configuredActionFeatures = Experiments.Features.FeatureRBFKernelActionsProd;

% action policy configurator
configuredPolicy = Experiments.ActionPolicies.PeriodicGaussianProcessPolicyConfigurator;
configuredPreprocessor= Experiments.Preprocessor.GridPreprocessorConfigurator('GridProcessor');

evaluationCriterion = Experiments.EvaluationCriterion();



evaluationCriterion.registerEvaluator(Evaluator.ReturnEvaluatorEvaluationSamplesAverage());
%evaluationCriterion.registerEvaluator(Evaluator.SaveDataAndTrial());




evaluate3_base_value = Experiments.Evaluation(...
    {'learner','actionPolicy','policyLearner', 'useStateFeaturesForPolicy','settings.RKHSparamsstate','settings.RKHSparamsactions','settings.numSamplesEvaluation','modelLearner'},{...
    @(trial) Learner.SteadyStateRL.RKHS_valueiteration(trial.dataManager, trial.modelLearner, trial.rewardFunction, trial.actionPolicy, 'states', 'ProdKernel'),...
    @(trial) Functions.ValueBasedPolicy(trial.dataManager,trial.rewardFunction, trial.stateActionFeatures),...
   @(trial)Learner.Learner(),...     %dummy 
   false,...
    [-1e-2 1 -0.6 1 -5 1 1], ... %0 indicates features should be optimized
    [-1e-2 1 1 1 1 1 -50], ... %0 indicates features should be optimized
     100,...
     @(trial) Learner.ModelLearner.RKHSModelLearner_unc(trial.dataManager, ...
                ':', trial.stateFeatures,...
                trial.nextStateFeatures,trial.stateActionFeatures),...
    %(dataManager, linearfunctionApproximator, varargin)
    },numIterations,numTrials);



evaluate3_base_value_grid = Experiments.Evaluation(...
    {'learner','actionPolicy','policyLearner', 'useStateFeaturesForPolicy',...
    'settings.RKHSparamsstate','settings.RKHSparamsactions','settings.numSamplesEvaluation',...
    'modelLearner','useGridPreprocessor','gridSize','settings.invTemperature',...
    'maxNumberKernelSamples','settings.maxSizeReferenceSet'},{...
    @(trial) Learner.SteadyStateRL.RKHS_valueiteration(trial.dataManager, trial.modelLearner, trial.rewardFunction, trial.actionPolicy, 'states', 'ProdKernel'),...
    @(trial, inputFeatures) Functions.ValueBasedPolicy(trial.dataManager,trial.rewardFunction, trial.stateActionFeatures),...
   @(dm, ap, sf)Learner.Learner(),...     %dummy 
   false,...
    [-1e-2 1 -0.6 1 -5 1 1], ... %0 indicates features should be optimized
    [-1e-2 1 1 1 1 1 -50], ... %0 indicates features should be optimized
     100,...
     @(trial)Learner.ModelLearner.RKHSModelLearner_unc(trial.dataManager, ...
                ':', trial.stateFeatures,...
                trial.nextStateFeatures,trial.stateActionFeatures),...
     true,...
     [12,12,12],...
     1.5,...
     3000,...
     3000,...
    %(dataManager, linearfunctionApproximator, varargin)
    },1,numTrials);

evaluate3_base_value2 = Experiments.Evaluation(...
    {'learner','actionPolicy','policyLearner', 'useStateFeaturesForPolicy','settings.RKHSparamsstate','settings.RKHSparamsactions','settings.numSamplesEvaluation','modelLearner'},{...
    @(trial) Learner.SteadyStateRL.RKHS_valueiteration2(trial.dataManager, trial.modelLearner, trial.rewardFunction, trial.actionPolicy, 'nextStates', 'ProdKernel'),...
    @(trial) Functions.ValueBasedPolicy(trial.dataManager,trial.rewardFunction, trial.stateActionFeatures),...
   @(trial)Learner.Learner(),...     %dummy 
   false,...
    [-1e-2 1 -0.6 1 -5 1 1], ... %0 indicates features should be optimized
    [-1e-2 1 1 1 1 1 -50], ... %0 indicates features should be optimized
     100,...
     @(trial) Learner.ModelLearner.RKHSEmbeddingStrengthLearner(trial.dataManager, ...
                ':', trial.stateFeatures,...
                trial.nextStateFeatures,trial.stateActionFeatures),...
    %(dataManager, linearfunctionApproximator, varargin)
    },numIterations,numTrials);

evaluate3_base_value_grid2 = Experiments.Evaluation(...
    {'learner','actionPolicy','policyLearner', 'useStateFeaturesForPolicy',...
    'settings.RKHSparamsstate','settings.RKHSparamsactions','settings.numSamplesEvaluation',...
    'modelLearner','useGridPreprocessor','gridSize','settings.invTemperature',...
    'maxNumberKernelSamples','settings.maxSizeReferenceSet','settings.nactions'},{...
    @(trial) Learner.SteadyStateRL.RKHS_valueiteration2(trial.dataManager, trial.modelLearner, trial.rewardFunction, trial.actionPolicy, 'nextStates', 'ProdKernel'),...
    @(trial, inputFeatures) Functions.ValueBasedPolicy(trial.dataManager,trial.rewardFunction, trial.stateActionFeatures),...
   @(dm, ap, sf)Learner.Learner(),...     %dummy 
   false,...
    [1e-2 1 0.6 1 5 1 1], ... %0 indicates features should be optimized
    [-1e-2 1 1 1 1 1 -50], ... %0 indicates features should be optimized
     100,...
     @(trial) Learner.ModelLearner.RKHSEmbeddingStrengthLearner(trial.dataManager, ...
                ':', trial.stateFeatures,...
                trial.nextStateFeatures,trial.stateActionFeatures),...
     true,...
     [19,11,11],...%was 25 17 13
     20,... %high temperature, essentially completely greedy
     6000,...
     6000,...
     25,...%number of actions in discretization
    %(dataManager, linearfunctionApproximator, varargin)
    },1,numTrials);

evaluate_temperatures=Experiments.Evaluation(...
    {'settings.invTemperature'},{1, 1.5,3},numIterations,numTrials);



evaluatetemperatures = Experiments.Evaluation.getCartesianProductOf([evaluate3_base_value, evaluate_temperatures]);
evaluatetemperatures2 = Experiments.Evaluation.getCartesianProductOf([evaluate3_base_value2, evaluate_temperatures]);
evaluate_grid = Experiments.Evaluation.getCartesianProductOf([evaluate3_base_value_grid]);
evaluate_grid2 = Experiments.Evaluation.getCartesianProductOf([evaluate3_base_value_grid2]);

 
experiment = Experiments.Experiment.createByNameNew(experimentName, category, ...
    {configuredTask, configuredPreprocessor, configuredFeatures, configuredActionFeatures, ...
    configuredPolicy, configuredLearner}, evaluationCriterion, 5);

%experiment.addEvaluation(evaluate1gp);
%experiment.addEvaluation(evaluatetemperatures2);
%experiment.addEvaluation(evaluatetemperatures);

experiment.addEvaluation(evaluate_grid2);
%experiment.addEvaluation(evalute_modellearners);



experiment.startLocal();
%experiment.startBatch();

